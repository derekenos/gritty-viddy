<html lang="en">

  <head>
    <meta charset="utf-8">

    <style>
     video,
     canvas {
       width: 1280px;
       height: 720px;
       border: solid #000 1px;
       display: none;
     }

     #final-wrapper {
       display: inline-block;
       position: relative;
     }

     #final-controls {
       position: absolute;
       top: 16px;
       right: 16px;
       background-color: rgba(0, 0, 0, .5);
       color: #fff;
       font-size: 16px;
       cursor: pointer;
     }

     canvas#final {
       display: block;
     }
    </style>

    <script src="ext/gpu-browser.min.js"></script>

    <script type="module">
     import Animator from "./animator.js"
     import CanvasRecorder from "./CanvasRecorder.js"
     import * as CPU_FILTERS from "./filters.js"
     import * as GPU_FILTERS from "./gpuFilters.js"

     const USE_GPU = true
     const FILTERS = USE_GPU ? GPU_FILTERS : CPU_FILTERS

     const dumpFrameToCanvas = (video, canvas) =>
       canvas.getContext("2d").drawImage(video, 0, 0, canvas.width, canvas.height)

     function initRecordControls (button, canvas, audioTrack) {
       button.textContent = "Start Recording"
       const recorder = new CanvasRecorder(canvas, audioTrack)
       button.addEventListener("click", e => {
         switch (recorder.state) {
           case "inactive":
             recorder.start()
             e.target.textContent = "Stop Recording"
             break
           case "recording":
             recorder.stop()
             e.target.textContent = "Start Recording"
             break
           default:
             throw new Error(`Unhandled recorder state: ${recorder.state}`)
             break
         }
       })
     }

     function init () {
       // Start video stream.
       const video = document.querySelector("video")
       const width = 1280
       const height = 720
       navigator.mediaDevices
         .getUserMedia({
           audio: true,
           video: { width, height },
         })
         .then(stream => {
           video.srcObject = stream
         })
       // Mute the video element audio.
       video.muted = true

       const canvasScale = USE_GPU ? 1 : 1 / 4
       const workCanvas = document.querySelector("canvas#work")
       workCanvas.width = width * canvasScale
       workCanvas.height = height * canvasScale
       const workCanvasCtx = workCanvas.getContext("2d")
       const finalCanvas = document.querySelector("canvas#final")
       finalCanvas.width = width * canvasScale
       finalCanvas.height = height * canvasScale
       const finalCanvasCtx = finalCanvas.getContext("2d")

       // Add fullscreen button handler.
       document.getElementById("final-fullscreen")
         .addEventListener("click", () => {
           finalCanvas.requestFullscreen()
         })

       function getProcessedImageData (filters = []) {
         dumpFrameToCanvas(video, workCanvas)
         const ctx = workCanvas.getContext("2d")
         let imageData = ctx.getImageData(0, 0, workCanvas.width, workCanvas.height)
         imageData = FILTERS.applyFilters(filters, imageData)
         return imageData
       }

       const anim = Animator({ stepsPerCycle: 50, oneShot: false })

       function process () {
         const filters = [
           [ FILTERS.thresholdFilter, [ Math.floor(anim.linearInterpolate( 128, 255 )) ] ],
           [ FILTERS.brightnessFilter, [ anim.linearInterpolate( 1, 6 ) ] ],
           //[ FILTERS.channelFilter, [ 1, 1, 1 ] ],
           //[ FILTERS.colorReducerFilter, [ 0xc0 ] ],
           [ FILTERS.invertFilter, [] ],
           [ FILTERS.rowBlankerFilter, [ Math.floor(anim.linearInterpolate( 2, 32 )) ] ],
           [ FILTERS.colBlankerFilter, [ 8 ] ],
           [ FILTERS.colorGainFilter, [ -1, 0, 1 ] ],
         ]
         finalCanvasCtx.putImageData(getProcessedImageData(filters), 0, 0)
         anim.step()
         requestAnimationFrame(process)
       }
       requestAnimationFrame(process)

       // Get the audio stream
       // from: https://stackoverflow.com/a/52400024/2327940
       const ctx = new AudioContext()
       const dest = ctx.createMediaStreamDestination()
       const sourceNode = ctx.createMediaElementSource(video)
       sourceNode.connect(dest);
       // Uncomment to hear the audio in realtime.
       // sourceNode.connect(ctx.destination);
       const audioTrack = dest.stream.getAudioTracks()[0];

       initRecordControls(
         document.getElementById("final-record"),
         document.querySelector("canvas#final"),
         audioTrack
       )
     }

     document.addEventListener("DOMContentLoaded", init)
    </script>

  </head>

  <body>
    <video autoplay="true"></video>
    <canvas id="work"></canvas>
    <div id="final-wrapper">
      <div id="final-controls">
        <button id="final-record"></button>
        <button id="final-fullscreen">&#8644;</button>
      </div>
      <canvas id="final"></canvas>
    </div>
  </body>

</html>
